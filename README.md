# ‚ö° FlashVSR+

**Optimized inference pipeline based on [FlashVSR](https://github.com/OpenImagingLab/FlashVSR) project**

**Authors:** Junhao Zhuang, Shi Guo, Xin Cai, Xiaohui Li, Yihao Liu, Chun Yuan, Tianfan Xue

**Modified:** lihaoyun6  

<a href='http://zhuang2002.github.io/FlashVSR'><img src='https://img.shields.io/badge/Project-Page-Green'></a> &nbsp;
<a href="https://huggingface.co/JunhaoZhuang/FlashVSR"><img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Model-blue"></a> &nbsp;
<a href="https://huggingface.co/datasets/JunhaoZhuang/VSR-120K"><img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Dataset-orange"></a> &nbsp;
<a href="https://arxiv.org/abs/2510.12747"><img src="https://img.shields.io/badge/arXiv-2510.12747-b31b1b.svg"></a>

**Your star means a lot for us to develop this project!** :star:

<img src="./teaser.jpg" />

---
### ü§î What's New?

- Replaced `Block-Sparse-Attention` with `Sparse_SageAttention` to avoid building complex cuda kernels.  
- With the new `tile_dit` method, you can even output 1080P video on 8GB of VRAM.   
- Support copying audio tracks to output files (powered by FFmpeg). 
- Introduced Blackwell GPU support for FlashVSR.  

---
### üöÄ Getting Started

Follow these steps to set up and run **FlashVSR** on your local machine:

> ‚ö†Ô∏è **Note:** This project is primarily designed and optimized for **4√ó video super-resolution**.  
> We **strongly recommend** using the **4√ó SR setting** to achieve better results and stability. ‚úÖ

#### 1Ô∏è‚É£ Clone the Repository

```bash
git clone https://github.com/lihaoyun6/FlashVSR_plus
cd FlashVSR_plus
````

#### 2Ô∏è‚É£ Set Up the Python Environment

Create and activate the environment:

```bash
conda create -n flashvsr
conda activate flashvsr
```

Install project dependencies:

```bash
# for CUDA 12.8
pip install -r requirements.txt --index-url https://download.pytorch.org/whl/cu128

# for CUDA 13.0
pip install -r requirements.txt --index-url https://download.pytorch.org/whl/cu130
```

#### 3Ô∏è‚É£ Download Model Weights

- When you run FlashVSR+ for the first time, it will automatically download all required models from HuggingFace.  

- You can also manually download all files from [FlashVSR](https://huggingface.co/JunhaoZhuang/FlashVSR) and put them in the following location:  

```
./models/FlashVSR/
‚îÇ
‚îú‚îÄ‚îÄ LQ_proj_in.ckpt                                   
‚îú‚îÄ‚îÄ TCDecoder.ckpt                                    
‚îú‚îÄ‚îÄ Wan2.1_VAE.pth                                    
‚îú‚îÄ‚îÄ diffusion_pytorch_model_streaming_dmd.safetensors 
‚îî‚îÄ‚îÄ README.md
```  

#### 4Ô∏è‚É£ Run Inference

CLI example:

```bash
python run.py -i ./inputs/example0.mp4 -s 4 ./
```
Or use gradio web ui:  

```bash
python webui.py
```

---

### ü§ó Feedback & Support

We welcome feedback and issues. Thank you for trying **FlashVSR+**

---

### üìÑ Acknowledgments

We gratefully acknowledge the following open-source projects:

* **FlashVSR** ‚Äî [https://github.com/OpenImagingLab/FlashVSR](https://github.com/OpenImagingLab/FlashVSR)
* **DiffSynth Studio** ‚Äî [https://github.com/modelscope/DiffSynth-Studio](https://github.com/modelscope/DiffSynth-Studio)
* **Sparse_SageAttention** ‚Äî [https://github.com/jt-zhang/Sparse\_SageAttention_API](https://github.com/jt-zhang/Sparse_SageAttention_API)
* **taehv** ‚Äî [https://github.com/madebyollin/taehv](https://github.com/madebyollin/taehv)

---

### üìû Contact

* **Junhao Zhuang**
  Email: [zhuangjh23@mails.tsinghua.edu.cn](mailto:zhuangjh23@mails.tsinghua.edu.cn)

---

### üìú Citation

```bibtex
@misc{zhuang2025flashvsrrealtimediffusionbasedstreaming,
      title={FlashVSR: Towards Real-Time Diffusion-Based Streaming Video Super-Resolution}, 
      author={Junhao Zhuang and Shi Guo and Xin Cai and Xiaohui Li and Yihao Liu and Chun Yuan and Tianfan Xue},
      year={2025},
      eprint={2510.12747},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2510.12747}, 
}
```
